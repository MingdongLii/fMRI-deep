{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def preds2label(pred_same, img1):\n",
    "    \"\"\"to detect the img0 label\n",
    "    \n",
    "    Arguments:\n",
    "        pred_same {tensor bs * 1} -- same_label of predict\n",
    "        img1 {tensor bs * 1} -- img1_label 训练集中用于val进行对比的样本\n",
    "    \n",
    "    Returns:\n",
    "        tensor bs*1 -- predict DX\n",
    "    \"\"\"   \n",
    "    img1_inverse = torch.where((img1!=0), torch.full_like(img1,0) , torch.full_like(img1,1))\n",
    "    predict_labels = torch.where((pred_same==1),img1, img1_reverse)\n",
    "    return predict_labels"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([3, 0, 1, 1, 0, 1, 3, 3, 1, 1])\ntensor([0, 0, 3, 1, 3, 1, 1, 3, 1, 1])\ntensor([0, 1, 0, 1, 0, 1, 0, 1, 1, 1], dtype=torch.uint8)\ntensor(6)\nok\n"
    }
   ],
   "source": [
    "same =      torch.tensor([[1],[0],[1],[0],[1],[0],[1],[1],[0],[1]])\n",
    "img1 =      torch.tensor([[0],[1],[3],[0],[3],[0],[1],[3],[0],[1]])\n",
    "true_img0 = torch.tensor([[3],[0],[1],[1],[0],[1],[3],[3],[1],[1]]).view(-1,)\n",
    "pred_img0 = predict_label(same, img1).view(-1,)\n",
    "print(true_img0)\n",
    "print(pred_img0)\n",
    "print(true_img0 == pred_img0)\n",
    "print(torch.sum(true_img0 == pred_img0))\n",
    "if torch.sum(true_img0 == pred_img0)>5:\n",
    "    print('ok')"
   ]
  },
  {
   "source": [
    "o1 = torch.randn(10,128)\n",
    "o2 = torch.randn(10,128)\n",
    "label = torch.tensor([1,0,1,1,1,1,0,1,0,0])\n",
    "print(F.pairwise_distance(o1, o2))\n",
    "res=torch.abs(o1 - o2)\n",
    "print(res.shape)\n",
    "label=label.tolist()\n",
    "print(label)\n",
    "result=torch.max(res,1)\n",
    "print(result)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([15.1433, 16.1523, 15.6637, 15.2236, 16.8706, 16.1007, 15.3622, 16.4850,\n        16.3121, 15.4365])\ntorch.Size([10, 128])\n[1, 0, 1, 1, 1, 1, 0, 1, 0, 0]\ntorch.return_types.max(\nvalues=tensor([3.8407, 4.1431, 4.7672, 4.3962, 4.1973, 3.5278, 3.9685, 4.2204, 3.6245,\n        4.2804]),\nindices=tensor([30, 99, 13, 84, 62, 95, 16, 44, 53,  5]))\n"
    }
   ],
   "metadata": {},
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "# MedicalNet-Tencent \n",
    "# https://github.com/Tencent/MedicalNet/blob/master/models/resnet.py\n",
    "# https://github.com/Tencent/MedicalNet/blob/master/model.py\n",
    "\n",
    "__all__ = [\n",
    "    'ResNet', 'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "    'resnet152', 'resnet200'\n",
    "]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        dilation=dilation,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        bias=False)\n",
    "\n",
    "\n",
    "def downsample_basic_block(x, planes, stride, no_cuda=False):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(\n",
    "        out.size(0), planes - out.size(1), out.size(2), out.size(3),\n",
    "        out.size(4)).zero_()\n",
    "    if not no_cuda:\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes, planes, kernel_size=3, stride=stride, dilation=dilation, padding=dilation, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layers,\n",
    "                 sample_input_D,\n",
    "                 sample_input_H,\n",
    "                 sample_input_W,\n",
    "                 num_seg_classes,\n",
    "                 shortcut_type='B',\n",
    "                 no_cuda = False):\n",
    "        self.inplanes = 64\n",
    "        self.no_cuda = no_cuda\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            1,\n",
    "            64,\n",
    "            kernel_size=7,\n",
    "            stride=(2, 2, 2),\n",
    "            padding=(3, 3, 3),\n",
    "            bias=False)\n",
    "            \n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 256, layers[2], shortcut_type, stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, 512, layers[3], shortcut_type, stride=1, dilation=4)\n",
    "\n",
    "        self.conv_seg = nn.Sequential(\n",
    "                                        nn.ConvTranspose3d(\n",
    "                                        512 * block.expansion,\n",
    "                                        32,\n",
    "                                        2,\n",
    "                                        stride=2\n",
    "                                        ),\n",
    "                                        nn.BatchNorm3d(32),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Conv3d(\n",
    "                                        32,\n",
    "                                        32,\n",
    "                                        kernel_size=3,\n",
    "                                        stride=(1, 1, 1),\n",
    "                                        padding=(1, 1, 1),\n",
    "                                        bias=False), \n",
    "                                        nn.BatchNorm3d(32),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Conv3d(\n",
    "                                        32,\n",
    "                                        num_seg_classes,\n",
    "                                        kernel_size=1,\n",
    "                                        stride=(1, 1, 1),\n",
    "                                        bias=False) \n",
    "                                        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride,\n",
    "                    no_cuda=self.no_cuda)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride=stride, dilation=dilation, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.conv_seg(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self,x1,x2):\n",
    "        output1 = self.forward_once(x1)\n",
    "        output2 = self.forward_once(x2)\n",
    "\n",
    "        return output1,output2\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet200(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:177: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
    }
   ],
   "source": [
    "model = resnet18(sample_input_D=49,\n",
    "                    sample_input_H = 59,\n",
    "                    sample_input_W = 47,\n",
    "                    num_seg_classes=2)\n",
    "model_dict = model.state_dict()\n",
    "# print(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.])), ('conv_seg.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('conv_seg.1.num_batches_tracked', tensor(0)), ('conv_seg.3.weight', tensor([[[[[ 4.7781e-02,  2.2600e-02,  3.1719e-02],\n           [ 4.6470e-02,  5.9064e-02,  9.0119e-02],\n           [-9.8603e-03,  4.5220e-02, -1.8025e-02]],\n\n          [[-2.9996e-02, -7.5031e-02,  3.6527e-02],\n           [ 5.3235e-02,  6.7657e-02,  7.4703e-02],\n           [ 5.4255e-03, -1.9369e-02, -4.7950e-02]],\n\n          [[ 6.0310e-03, -5.0718e-03,  8.9277e-02],\n           [ 1.9587e-02,  1.3265e-03, -4.4698e-02],\n           [ 3.5071e-02, -7.3248e-02,  5.7715e-03]]],\n\n\n         [[[-2.8861e-03, -4.3450e-02, -2.8001e-02],\n           [ 1.0777e-01,  9.9036e-03,  3.0317e-02],\n           [ 3.2657e-03, -4.4497e-02, -3.7148e-02]],\n\n          [[-1.1551e-02, -5.0359e-02,  3.7234e-02],\n           [ 9.5055e-03, -8.7731e-03, -3.7838e-02],\n           [ 8.3466e-02,  7.6593e-02, -3.3739e-02]],\n\n          [[-1.3866e-01, -2.6022e-05,  5.4146e-02],\n           [ 1.8527e-03,  4.0354e-03, -2.5352e-02],\n           [-4.9490e-02,  3.9605e-02,  7.1061e-03]]],\n\n\n         [[[-1.3865e-02,  1.2163e-01, -6.7173e-03],\n           [ 6.3398e-02, -4.2231e-02,  3.9770e-02],\n           [ 5.7228e-02, -4.8378e-02, -8.7472e-02]],\n\n          [[-2.7160e-02, -8.4036e-04, -1.6499e-02],\n           [-1.7956e-02,  1.1758e-02,  3.4963e-04],\n           [-2.3579e-02, -1.2707e-02, -2.6792e-02]],\n\n          [[ 6.6281e-03,  6.7738e-02, -2.9035e-03],\n           [-3.2127e-02, -6.8712e-02, -2.5491e-03],\n           [ 1.3256e-02,  1.1664e-02,  4.1510e-02]]],\n\n\n         ...,\n\n\n         [[[ 2.3573e-03,  2.1473e-02, -2.6865e-02],\n           [-2.3124e-02, -1.5219e-03,  7.9223e-02],\n           [ 1.2987e-02,  5.2466e-02, -6.4237e-03]],\n\n          [[ 5.0046e-02, -1.8251e-02,  3.3671e-02],\n           [-3.0649e-02, -2.9826e-02,  3.0434e-02],\n           [ 1.0567e-01, -4.8430e-02, -5.2411e-02]],\n\n          [[ 5.3697e-02, -1.3764e-02,  3.1284e-02],\n           [ 3.9611e-02,  1.6335e-02,  5.3684e-02],\n           [-2.5236e-04, -1.1170e-01,  2.0019e-02]]],\n\n\n         [[[-4.1344e-02,  2.2915e-02,  2.2247e-02],\n           [-4.7667e-02, -5.7030e-03, -5.7203e-02],\n           [-4.0917e-02,  8.7183e-02,  3.5969e-02]],\n\n          [[ 2.0504e-02,  1.0871e-02,  1.5085e-01],\n           [ 2.3705e-02,  1.2823e-02, -5.4281e-02],\n           [-3.0468e-02, -1.2090e-03,  5.9700e-02]],\n\n          [[ 3.8001e-03,  5.7536e-02, -2.8986e-02],\n           [ 2.8642e-02, -8.6824e-02,  1.1239e-02],\n           [ 1.2229e-02, -6.4282e-02, -7.3780e-02]]],\n\n\n         [[[ 4.3132e-02, -5.2922e-02, -1.7111e-02],\n           [-6.7780e-04,  1.0345e-01,  4.6731e-03],\n           [-1.6162e-02,  6.0270e-02, -4.7321e-02]],\n\n          [[ 3.6835e-02,  2.2235e-02, -5.0290e-02],\n           [ 3.3730e-02,  5.7191e-03, -2.2801e-02],\n           [ 3.6475e-02, -5.2715e-02,  1.0429e-01]],\n\n          [[-3.5023e-02,  5.8986e-02,  3.7360e-02],\n           [-9.3332e-02, -2.3502e-02,  8.1851e-02],\n           [ 5.5787e-02,  1.7050e-02,  1.2048e-01]]]],\n\n\n\n        [[[[ 1.7193e-02,  3.2307e-02,  6.3737e-02],\n           [ 5.9354e-02, -3.7657e-03, -4.2734e-02],\n           [ 2.3165e-02,  8.4758e-03,  1.9796e-02]],\n\n          [[ 5.8808e-03,  2.2121e-02, -1.4256e-02],\n           [ 4.2670e-02,  8.4416e-02,  6.1417e-02],\n           [-9.1424e-02, -3.0183e-02, -5.5439e-02]],\n\n          [[ 8.7752e-02, -7.4601e-02,  5.6257e-02],\n           [ 1.4566e-02, -9.4102e-02, -1.8610e-02],\n           [-4.4566e-02,  3.6267e-03,  3.0659e-02]]],\n\n\n         [[[ 4.8856e-02, -3.4379e-02, -4.8494e-02],\n           [-1.9359e-02,  2.9321e-03,  1.7136e-03],\n           [ 3.3838e-02, -5.5244e-03,  1.7715e-02]],\n\n          [[-2.8702e-02, -1.1952e-02,  6.5666e-03],\n           [-5.1944e-02, -2.5847e-02, -7.6517e-02],\n           [ 4.5311e-02, -2.3869e-02, -2.7772e-02]],\n\n          [[ 1.5051e-02,  5.1209e-03, -5.1350e-02],\n           [-1.0956e-02,  2.6493e-02, -4.4400e-02],\n           [-1.0668e-02, -1.9939e-02, -1.8116e-02]]],\n\n\n         [[[ 4.7523e-02,  3.5231e-02, -8.7829e-02],\n           [-3.0115e-02, -5.0399e-02,  1.3327e-02],\n           [-3.3461e-02,  3.4440e-02,  5.5556e-03]],\n\n          [[ 3.1884e-02,  4.7621e-02,  4.1088e-02],\n           [-3.0978e-02,  6.1062e-02, -4.3740e-03],\n           [-2.9740e-02, -1.0359e-02, -1.1105e-02]],\n\n          [[ 3.7907e-02, -2.1878e-02,  3.5339e-02],\n           [ 2.9456e-02, -7.7745e-02, -5.3995e-02],\n           [-6.4334e-02,  1.9594e-02, -4.5369e-04]]],\n\n\n         ...,\n\n\n         [[[ 6.2146e-02, -3.2104e-03,  4.2391e-02],\n           [ 5.7585e-02,  3.7011e-02, -2.0745e-02],\n           [-1.3577e-02, -6.2333e-03,  3.5487e-02]],\n\n          [[ 4.1649e-02,  3.7616e-02, -1.6831e-03],\n           [-2.6767e-02,  7.5942e-02,  3.5883e-02],\n           [ 1.0315e-01,  4.8516e-02,  2.1347e-04]],\n\n          [[-4.0244e-02,  3.1030e-02,  2.0255e-03],\n           [ 5.7437e-02, -4.7088e-02, -5.3969e-02],\n           [ 1.5353e-02,  2.8273e-02, -4.0317e-02]]],\n\n\n         [[[-8.5121e-03,  8.7359e-02, -7.9602e-02],\n           [-5.1945e-03, -3.5809e-02, -1.1990e-01],\n           [ 3.5127e-02, -5.3575e-02,  2.4873e-02]],\n\n          [[ 2.7762e-02, -2.1042e-02,  4.1990e-03],\n           [-2.0129e-02,  8.2537e-03,  1.3877e-02],\n           [ 1.7723e-02,  3.6822e-02,  7.3900e-02]],\n\n          [[ 6.4309e-02, -1.3825e-03, -2.2155e-02],\n           [ 1.4457e-02,  2.3766e-02, -5.4018e-02],\n           [-3.6307e-02, -5.1960e-02, -4.0426e-02]]],\n\n\n         [[[ 6.5534e-02,  1.6604e-02,  3.2037e-02],\n           [-2.5166e-02,  7.4434e-02,  3.6348e-02],\n           [ 6.2341e-02,  1.0178e-01, -6.4201e-02]],\n\n          [[ 5.2446e-02,  3.1069e-02, -4.0106e-02],\n           [ 4.8761e-04,  1.0147e-02, -1.3707e-02],\n           [-1.0504e-01,  4.4192e-02, -4.2757e-02]],\n\n          [[ 1.3278e-01,  1.5864e-03, -4.5136e-03],\n           [-3.4219e-02, -3.3083e-04, -2.1401e-02],\n           [ 9.8399e-03, -2.6554e-02, -2.6269e-02]]]],\n\n\n\n        [[[[ 9.0858e-03,  1.8009e-02, -7.5888e-02],\n           [ 7.4691e-02,  5.0926e-02, -1.0693e-02],\n           [ 4.0251e-02, -1.6889e-02,  2.5135e-02]],\n\n          [[ 3.1525e-02, -2.3020e-02,  1.6353e-02],\n           [-5.6604e-02,  4.5501e-03,  5.1635e-02],\n           [-2.5891e-02, -1.9901e-02, -1.3336e-02]],\n\n          [[ 6.6177e-02, -2.6491e-02, -4.1938e-02],\n           [ 9.8038e-02, -7.6156e-03,  1.5864e-02],\n           [-2.0724e-02, -1.0083e-01, -1.9408e-02]]],\n\n\n         [[[ 2.1603e-02,  3.3409e-03, -9.9981e-02],\n           [ 1.0321e-01, -8.1281e-04, -9.6519e-03],\n           [ 6.8957e-02, -4.4638e-02, -2.0800e-02]],\n\n          [[ 2.0335e-02, -8.1452e-02,  8.0277e-02],\n           [ 6.0698e-02, -3.8853e-02,  6.4866e-02],\n           [-9.6348e-03, -2.0161e-02,  5.3390e-02]],\n\n          [[-7.8664e-02, -5.0785e-02, -7.5010e-02],\n           [-3.2227e-02,  9.4191e-02,  3.8023e-02],\n           [ 7.8542e-02, -2.1098e-02,  6.6007e-03]]],\n\n\n         [[[-1.5973e-02,  4.1558e-02,  3.5781e-02],\n           [-1.0422e-03,  1.1514e-02,  2.4407e-02],\n           [-1.2469e-02,  2.2656e-02, -3.5821e-02]],\n\n          [[ 1.1937e-01, -1.8313e-03, -4.4904e-02],\n           [ 7.5308e-02, -2.4270e-02,  1.4580e-02],\n           [-7.0946e-02,  3.0293e-02,  1.7781e-02]],\n\n          [[-7.7534e-02,  9.0346e-02, -2.0830e-02],\n           [ 3.0253e-02,  1.2481e-02, -8.2987e-02],\n           [ 3.9194e-02, -5.1967e-02, -6.1853e-03]]],\n\n\n         ...,\n\n\n         [[[-7.6095e-03, -1.3832e-02,  1.6340e-02],\n           [-7.9646e-03, -1.5943e-02, -4.5002e-02],\n           [-5.1622e-02,  3.5301e-02, -3.2093e-02]],\n\n          [[-7.3787e-03, -1.8154e-02, -4.5907e-02],\n           [ 6.0313e-02, -1.3362e-01,  1.8245e-02],\n           [-5.1103e-02,  5.8038e-02,  2.0795e-02]],\n\n          [[-3.3906e-02,  4.4879e-02,  2.0488e-02],\n           [ 2.0150e-02,  8.4876e-02,  3.4729e-02],\n           [-8.5793e-02, -7.1768e-02, -7.6330e-02]]],\n\n\n         [[[ 2.7232e-02, -9.7838e-03, -4.2380e-03],\n           [-3.4686e-02,  6.6380e-02, -1.3825e-02],\n           [ 1.8291e-02,  2.8548e-03, -4.9343e-02]],\n\n          [[ 1.7609e-02, -4.8196e-04,  3.0012e-02],\n           [ 2.5415e-02, -2.5345e-02,  2.4458e-02],\n           [-1.7432e-02,  1.1514e-02, -6.6446e-02]],\n\n          [[-4.1874e-02,  4.3807e-02,  4.1006e-02],\n           [ 4.3863e-02, -4.7150e-03, -5.8211e-02],\n           [-5.6095e-02, -3.4357e-02, -2.9294e-02]]],\n\n\n         [[[ 1.7034e-01,  6.6202e-03, -6.4314e-02],\n           [ 4.0630e-04,  8.4048e-02, -8.2712e-02],\n           [ 1.1690e-02,  7.1737e-03,  6.9553e-03]],\n\n          [[ 5.0852e-02,  1.8735e-02,  6.6779e-02],\n           [-1.4930e-02, -6.1144e-02,  1.1039e-03],\n           [ 5.6702e-02,  6.7641e-03, -1.1016e-02]],\n\n          [[-3.8217e-02, -6.5150e-03, -2.2856e-02],\n           [ 7.7300e-02, -6.0006e-02,  7.8667e-03],\n           [-5.7813e-03,  8.9308e-03,  1.7128e-02]]]],\n\n\n\n        ...,\n\n\n\n        [[[[-1.3636e-02,  1.5496e-02,  4.9601e-02],\n           [ 7.7095e-04, -3.4435e-02,  1.0299e-01],\n           [ 4.8820e-02, -2.5905e-02,  5.5694e-02]],\n\n          [[-3.7120e-02,  4.5727e-02,  1.6591e-02],\n           [ 2.1970e-02,  1.9375e-03,  5.9958e-02],\n           [-2.5009e-02,  8.3038e-02, -3.9368e-02]],\n\n          [[ 2.6851e-02, -1.4480e-01, -1.8023e-02],\n           [ 2.3932e-02, -7.4058e-02, -5.9631e-02],\n           [-2.1484e-02, -3.8429e-02, -1.3932e-02]]],\n\n\n         [[[-6.8803e-02,  9.5971e-03,  5.1573e-02],\n           [-7.4000e-02,  2.8379e-03, -3.4509e-02],\n           [-4.2542e-02, -2.7389e-02, -1.1652e-02]],\n\n          [[ 5.1947e-02,  7.1824e-03, -2.6181e-02],\n           [ 1.0753e-02, -2.6608e-02,  9.8860e-02],\n           [-1.3935e-02, -6.5405e-02, -2.2150e-03]],\n\n          [[ 6.1244e-02,  5.4510e-02,  1.1043e-02],\n           [-2.4090e-03,  5.9460e-02, -1.6094e-02],\n           [-4.0572e-02, -1.0391e-02,  4.5565e-02]]],\n\n\n         [[[-3.1429e-03,  6.3762e-02,  1.1044e-02],\n           [ 6.0170e-03, -9.0531e-02,  1.3816e-02],\n           [ 2.7052e-02, -4.3083e-02, -5.2992e-02]],\n\n          [[ 2.2050e-03, -2.6810e-02, -5.1003e-03],\n           [-1.5837e-02, -3.4649e-02, -1.1755e-02],\n           [-4.0836e-02,  8.0620e-02, -2.9386e-02]],\n\n          [[ 1.2590e-01,  4.8963e-03, -1.0052e-01],\n           [ 1.2358e-02, -1.4731e-02, -2.6533e-02],\n           [-8.4599e-02,  3.5797e-02,  4.4184e-03]]],\n\n\n         ...,\n\n\n         [[[ 1.7592e-02, -7.7435e-02,  1.6501e-02],\n           [ 2.3919e-02,  2.8734e-02, -3.0139e-02],\n           [ 6.4031e-02, -6.0604e-02, -1.4935e-02]],\n\n          [[-1.2229e-01, -8.1224e-02,  3.6464e-02],\n           [-5.6304e-02,  1.3177e-02, -4.6361e-02],\n           [ 2.3920e-02, -5.1337e-02,  1.9705e-03]],\n\n          [[-2.2975e-02, -6.5003e-02, -2.7072e-02],\n           [-4.1623e-02, -1.9275e-02,  1.2967e-02],\n           [-8.7060e-03,  6.2924e-02,  3.3755e-02]]],\n\n\n         [[[-3.9568e-02,  1.7227e-02, -4.2069e-03],\n           [ 1.0372e-02, -3.3679e-02,  6.6251e-02],\n           [ 2.3403e-02, -4.2168e-02, -1.1446e-02]],\n\n          [[ 7.5689e-02,  5.6078e-02, -7.8565e-02],\n           [ 1.6179e-02, -1.7289e-02,  3.5472e-02],\n           [ 8.6447e-02, -3.1893e-02, -3.0244e-02]],\n\n          [[-3.0533e-02, -1.2365e-02,  2.9573e-02],\n           [ 4.8114e-02, -5.3848e-03,  2.0962e-02],\n           [-5.5711e-02,  1.5706e-02, -3.1675e-02]]],\n\n\n         [[[-1.1591e-01,  6.0024e-03, -5.8504e-02],\n           [-3.6695e-02,  1.9351e-02, -2.5455e-02],\n           [ 9.2209e-04,  4.0799e-02, -3.3057e-02]],\n\n          [[-1.8355e-02, -7.5207e-02,  2.1417e-02],\n           [-5.4157e-02,  3.4863e-03, -9.2061e-03],\n           [ 3.0824e-02,  8.1183e-02, -4.3721e-02]],\n\n          [[ 7.4341e-02,  6.9418e-03, -2.1795e-02],\n           [-7.0663e-02,  7.9297e-03,  5.1879e-02],\n           [ 3.7548e-02,  8.8388e-02, -6.8287e-02]]]],\n\n\n\n        [[[[ 3.3144e-02, -4.3239e-02,  6.3287e-02],\n           [-8.1086e-02, -3.4171e-03,  5.7287e-02],\n           [-7.2871e-02,  9.9032e-02, -5.7880e-02]],\n\n          [[ 2.9810e-02,  5.4276e-02, -7.0455e-03],\n           [-8.0028e-02,  3.4622e-02,  3.8072e-02],\n           [-2.4254e-03, -2.7613e-02,  4.0641e-02]],\n\n          [[-2.0942e-02, -6.1318e-02, -5.1647e-03],\n           [ 3.3830e-02, -9.3759e-03,  3.4063e-02],\n           [ 8.6627e-03, -6.2735e-02,  1.3155e-02]]],\n\n\n         [[[ 2.8561e-02, -8.2249e-03, -2.5684e-02],\n           [-1.3207e-02, -1.1039e-01, -6.2593e-02],\n           [-3.8426e-02, -6.8457e-02, -2.3029e-02]],\n\n          [[-2.7116e-02, -1.6096e-02, -5.0928e-02],\n           [ 4.7049e-03,  4.8377e-02, -1.5128e-02],\n           [ 2.2390e-02,  1.1102e-02, -2.8664e-02]],\n\n          [[ 3.0106e-02,  3.5451e-02,  5.6565e-03],\n           [-7.2275e-02, -5.9176e-02,  1.1444e-02],\n           [ 4.2391e-02, -2.3877e-03, -4.2724e-02]]],\n\n\n         [[[ 2.8769e-02,  6.6595e-03, -2.5868e-02],\n           [-6.8304e-02,  3.8875e-02, -5.7707e-02],\n           [-4.1106e-02,  1.1973e-01, -1.3034e-02]],\n\n          [[ 2.0459e-02,  6.7141e-02,  9.4565e-02],\n           [ 1.1001e-02, -1.8719e-02,  4.1398e-02],\n           [ 2.3501e-02,  1.4138e-02,  1.6236e-02]],\n\n          [[-1.1769e-03, -2.2294e-02,  6.2798e-02],\n           [-3.7225e-02,  1.4210e-02, -1.3744e-02],\n           [-2.0104e-02, -2.6016e-02,  1.1672e-01]]],\n\n\n         ...,\n\n\n         [[[-4.4341e-02, -5.6679e-02,  1.7420e-02],\n           [ 1.8935e-02,  2.9597e-02, -1.2218e-01],\n           [-5.4873e-03, -1.2941e-03, -5.5451e-02]],\n\n          [[ 2.8769e-02,  7.6563e-02,  2.2265e-02],\n           [ 1.2689e-01,  2.2390e-02,  2.3202e-02],\n           [ 4.8643e-02,  2.0477e-02,  3.2365e-02]],\n\n          [[ 2.3081e-03,  9.6059e-02,  7.1174e-02],\n           [-4.2900e-02,  6.4722e-02,  3.0746e-02],\n           [-3.1182e-02,  4.7564e-02,  1.2131e-02]]],\n\n\n         [[[ 8.4503e-02, -3.6074e-02, -4.7079e-02],\n           [ 7.9320e-02,  2.0029e-02, -4.6320e-02],\n           [ 1.3114e-02,  5.9443e-02, -4.9422e-02]],\n\n          [[ 2.9775e-02,  2.5062e-02, -3.4139e-02],\n           [-8.3697e-02, -1.3036e-02, -4.1176e-02],\n           [-1.6975e-02, -7.0920e-02, -4.4732e-03]],\n\n          [[-5.5985e-02,  2.9530e-02,  6.9910e-02],\n           [-2.9168e-02, -9.2168e-02, -2.8344e-03],\n           [ 1.8730e-02,  6.9845e-02, -2.8750e-02]]],\n\n\n         [[[ 1.6414e-02, -1.0738e-01, -3.7336e-02],\n           [-3.9365e-02, -6.6259e-03, -9.7458e-02],\n           [-1.8028e-03,  9.3318e-02,  9.9172e-02]],\n\n          [[-2.9936e-02,  8.3527e-02,  3.3909e-02],\n           [-7.7833e-02, -7.0951e-02,  7.6868e-02],\n           [ 7.7331e-02,  7.5547e-02, -8.0258e-02]],\n\n          [[-1.2969e-02, -2.4054e-02,  6.3371e-02],\n           [-1.2774e-02, -2.6670e-02,  6.6474e-02],\n           [-1.2041e-03,  2.5875e-02, -3.3898e-02]]]],\n\n\n\n        [[[[-1.9555e-02, -2.1178e-02,  3.8705e-02],\n           [-2.9482e-02,  4.9060e-02,  3.7335e-02],\n           [ 1.6567e-02, -9.1124e-02, -2.3676e-02]],\n\n          [[ 5.6770e-02,  1.0523e-01, -2.4924e-03],\n           [-1.0641e-02,  1.4930e-02,  3.4323e-03],\n           [ 3.3040e-02, -6.4395e-02,  3.2518e-02]],\n\n          [[ 6.5408e-03,  5.6461e-02,  2.1609e-02],\n           [-4.9909e-02,  1.3313e-01,  3.1899e-02],\n           [-7.3993e-02, -3.5957e-03, -1.0166e-02]]],\n\n\n         [[[ 6.0612e-02, -3.0555e-02, -8.5213e-03],\n           [ 2.4867e-02,  1.6071e-02,  9.9494e-03],\n           [-1.0865e-01, -2.3834e-02, -1.4877e-02]],\n\n          [[ 5.1059e-02,  1.2056e-02,  2.3039e-02],\n           [-6.7194e-03, -7.2634e-03, -5.4946e-02],\n           [ 7.4744e-02, -3.4701e-02,  2.2839e-02]],\n\n          [[ 9.8456e-02, -2.9438e-02, -7.9078e-03],\n           [-7.4956e-04, -5.2107e-02, -7.9475e-03],\n           [ 2.2646e-02,  8.5028e-03,  3.6355e-02]]],\n\n\n         [[[-8.0603e-02, -6.8202e-02,  1.2222e-02],\n           [-5.4035e-03,  5.2132e-02,  6.4317e-02],\n           [-8.4345e-02,  5.8119e-02, -1.1330e-02]],\n\n          [[-1.3284e-02,  3.3490e-02,  3.6551e-03],\n           [ 5.7427e-02,  8.8577e-03, -9.5661e-02],\n           [ 8.2492e-02, -9.9959e-02,  7.5458e-02]],\n\n          [[-2.0132e-02, -3.1943e-02,  5.5070e-02],\n           [-2.4225e-02, -1.9360e-03,  3.3036e-02],\n           [ 1.9749e-02, -6.6953e-02,  3.4668e-02]]],\n\n\n         ...,\n\n\n         [[[ 1.2054e-02, -2.6771e-02, -6.1733e-02],\n           [ 2.9408e-02,  3.9975e-02,  2.6843e-02],\n           [ 5.4880e-02,  1.9611e-02,  1.3610e-02]],\n\n          [[-3.6771e-02,  4.6083e-02, -2.7632e-02],\n           [ 4.1619e-02,  4.3870e-02, -6.3287e-02],\n           [ 3.0228e-02, -2.9497e-02,  1.7036e-02]],\n\n          [[ 2.0204e-05,  3.4126e-02,  2.6557e-02],\n           [-1.0040e-02, -1.7913e-02,  2.7035e-02],\n           [-3.3878e-02, -6.1166e-02, -5.8521e-02]]],\n\n\n         [[[ 8.5479e-02,  7.6664e-02, -2.9008e-02],\n           [ 8.3093e-02,  4.2890e-02,  2.2172e-02],\n           [-1.4304e-01, -7.0919e-02, -7.4748e-02]],\n\n          [[ 3.1857e-02, -4.9839e-02,  4.3785e-02],\n           [-9.2116e-02,  2.2825e-03, -2.7540e-02],\n           [ 8.3294e-03,  1.5087e-03, -2.5758e-02]],\n\n          [[-9.0907e-03, -4.6134e-02,  7.2316e-02],\n           [ 5.8045e-02, -7.4758e-03, -3.4790e-02],\n           [ 2.8396e-02,  4.5808e-02,  3.0207e-02]]],\n\n\n         [[[-2.2296e-02,  8.4418e-02,  2.7418e-02],\n           [ 5.2096e-03,  1.9173e-02, -9.0665e-04],\n           [-5.4823e-02,  4.7769e-03,  7.8965e-02]],\n\n          [[-8.2838e-02,  7.3093e-03, -3.3187e-03],\n           [-3.0594e-02,  3.2744e-02,  8.2992e-02],\n           [-2.0333e-02,  5.2605e-03, -1.6121e-02]],\n\n          [[-7.7235e-02,  5.5951e-02,  4.1162e-02],\n           [-6.8559e-02, -5.4934e-02, -1.1934e-02],\n           [-4.9957e-02, -2.4386e-02, -1.3225e-01]]]]])), ('conv_seg.4.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('conv_seg.4.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.])), ('conv_seg.4.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.])), ('conv_seg.4.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('conv_seg.4.num_batches_tracked', tensor(0)), ('conv_seg.6.weight', tensor([[[[[-1.5698]]],\n\n\n         [[[-1.3704]]],\n\n\n         [[[ 1.3053]]],\n\n\n         [[[-1.3112]]],\n\n\n         [[[ 3.4847]]],\n\n\n         [[[-0.6713]]],\n\n\n         [[[-0.6506]]],\n\n\n         [[[-0.2980]]],\n\n\n         [[[-0.5995]]],\n\n\n         [[[ 0.8650]]],\n\n\n         [[[ 0.0144]]],\n\n\n         [[[ 0.2343]]],\n\n\n         [[[-0.4723]]],\n\n\n         [[[ 0.3120]]],\n\n\n         [[[-0.8433]]],\n\n\n         [[[ 0.4498]]],\n\n\n         [[[-0.6525]]],\n\n\n         [[[-1.2577]]],\n\n\n         [[[-0.0423]]],\n\n\n         [[[ 1.2418]]],\n\n\n         [[[-1.3221]]],\n\n\n         [[[-0.9546]]],\n\n\n         [[[-0.5525]]],\n\n\n         [[[ 0.3851]]],\n\n\n         [[[ 0.8513]]],\n\n\n         [[[-0.9214]]],\n\n\n         [[[ 0.2786]]],\n\n\n         [[[-0.4949]]],\n\n\n         [[[-0.1414]]],\n\n\n         [[[ 0.9071]]],\n\n\n         [[[ 2.0559]]],\n\n\n         [[[ 0.9923]]]],\n\n\n\n        [[[[-0.0928]]],\n\n\n         [[[-1.3187]]],\n\n\n         [[[-0.4278]]],\n\n\n         [[[ 0.8894]]],\n\n\n         [[[-0.1709]]],\n\n\n         [[[-0.6994]]],\n\n\n         [[[ 0.9740]]],\n\n\n         [[[-2.3518]]],\n\n\n         [[[-0.1888]]],\n\n\n         [[[-1.0186]]],\n\n\n         [[[-0.4449]]],\n\n\n         [[[ 0.1085]]],\n\n\n         [[[-0.2366]]],\n\n\n         [[[ 1.6807]]],\n\n\n         [[[-0.2204]]],\n\n\n         [[[ 1.2189]]],\n\n\n         [[[ 1.2272]]],\n\n\n         [[[-0.2683]]],\n\n\n         [[[-2.8224]]],\n\n\n         [[[ 1.8148]]],\n\n\n         [[[-0.8066]]],\n\n\n         [[[ 0.0910]]],\n\n\n         [[[ 0.6072]]],\n\n\n         [[[ 1.0180]]],\n\n\n         [[[ 0.3324]]],\n\n\n         [[[-0.5336]]],\n\n\n         [[[-0.0171]]],\n\n\n         [[[-1.2726]]],\n\n\n         [[[-1.6115]]],\n\n\n         [[[ 0.6021]]],\n\n\n         [[[ 0.4183]]],\n\n\n         [[[-0.8244]]]]]))])\n"
    }
   ],
   "source": [
    "pretrained_dict = torch.load('./deep/base_siam/weights/MedicalNet/pretrain/resnet_18.pth')\n",
    "model_dict = model.state_dict()\n",
    "print(model_dict)"
   ]
  }
 ]
}